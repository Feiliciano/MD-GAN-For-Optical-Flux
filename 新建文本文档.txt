 虽然 MDGAN 能够生成生动的运动和逼真的视频，但很难训练这样的两阶段模型，并且缺乏多样化的视频生成能力，这限制了该方法的实用性



我们加入了光流信息，并加入归一化运动矢量来控制生成过程，可以生成高质量和多样化的延时视频。

从单个风景图像生成多样化的延时视频

两个子模块组成：光流编码器和动态视频生成器

光流编码器引入无监督光流估计方法来获取连续图像之间的运动图，并将它们编码为归一化的运动向量。在测试阶段，我们排除了流估计和流编码的过程，
直接从归一化分布中采样作为运动向量，减少了网络计算开销，同时提供了多样化的运动信息。
动态视频生成器包含分别从运动向量和单个图像中学习的运动和内容流，以及分别学习共享内容特征和构建视频帧的编码器和解码器。


我们在训练阶段应用内容损失、运动损失和对抗损失，确保高质量、动态和多样化的视频生成


MDGAN  提出了一种基于 3D 卷积的两阶段方法来生成逼真的高分辨率延时视频。我们的模型遵循 GAN 的思想，并在生成视频时考虑了额外的运动信息。

MDGAN 采用两阶段网络来生成长期的未来帧。它在第一阶段为每一帧生成真实内容的视频，然后对第一阶段生成的视频进行细化。

Sky Time-lapse。 Sky Time-lapse  包括 5000 多个延时视频，这些视频从 Youtube 剪辑成短片，
其中包含动态的天空场景，例如云朵移动的多云天空和星星移动的星空。 在整个数据集中，有 35,392 个训练视频剪辑和 2,815 个测试视频剪辑，每个包含 32 帧。 
每帧的原始大小为 3 × 640 × 360，我们将其调整为大小为 3 × 128 × 128 的正方形图像，并将颜色值归一化为 [-1, 1]。